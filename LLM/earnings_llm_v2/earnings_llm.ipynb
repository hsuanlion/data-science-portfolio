{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73290c37",
   "metadata": {},
   "source": [
    "# TSLAè²¡å ±åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05319b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/7clwcy050c7gyjz5lqt8kk_00000gn/T/ipykernel_3193/3249585533.py:18: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import faithfulness, answer_relevancy\n",
      "/var/folders/rs/7clwcy050c7gyjz5lqt8kk_00000gn/T/ipykernel_3193/3249585533.py:18: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import faithfulness, answer_relevancy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAGAS ç›¸é—œå°å…¥\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy\n",
    "from datasets import Dataset\n",
    "\n",
    "# è‡ªå‹•è®€å– .env\n",
    "load_dotenv()\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ”‘ API KEY èˆ‡å…¨åŸŸè®Šæ•¸è¨­å®š\n",
    "# ==========================================\n",
    "apiKey = os.getenv(\"OPENAI_API_KEY\") or \"\"\n",
    "TICKER = \"TSLA\"\n",
    "HEADERS = {'User-Agent': \"Financial Analyst bot (yourname@company.com)\"}\n",
    "\n",
    "# --- 1. SEC API: ç²å–æœ€æ–°è²¡å‹™ Fact èˆ‡ Tesla å®˜ç¶² PDF é€£çµ ---\n",
    "\n",
    "def get_latest_sec_data():\n",
    "    res = requests.get(\"https://www.sec.gov/files/company_tickers.json\", headers=HEADERS)\n",
    "    cik_data = res.json()\n",
    "    cik = next(str(v['cik_str']).zfill(10) for v in cik_data.values() if v['ticker'] == TICKER)\n",
    "    \n",
    "    sub_url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    sub_data = requests.get(sub_url, headers=HEADERS).json()\n",
    "    recent = sub_data.get('filings', {}).get('recent', {})\n",
    "    \n",
    "    latest_info = {}\n",
    "    for i, form in enumerate(recent.get('form', [])):\n",
    "        if form in ['10-K', '10-Q']:\n",
    "            acc_no_raw = recent['accessionNumber'][i]\n",
    "            acc_no = acc_no_raw.replace('-', '')\n",
    "            report_date = recent['reportDate'][i].replace('-', '')\n",
    "            \n",
    "            pdf_url = f\"https://ir.tesla.com/_flysystem/s3/sec/{acc_no}/tsla-{report_date}-gen.pdf\"\n",
    "            \n",
    "            latest_info = {\n",
    "                \"ticker\": TICKER,\n",
    "                \"form\": form,\n",
    "                \"acc_no\": acc_no_raw,\n",
    "                \"date\": recent['reportDate'][i],\n",
    "                \"url\": pdf_url,\n",
    "                \"filename\": f\"TSLA_{report_date}_{form}.pdf\"\n",
    "            }\n",
    "            break\n",
    "\n",
    "    fact_url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    fact_data = requests.get(fact_url, headers=HEADERS).json()\n",
    "    \n",
    "    def get_latest_fact(concept):\n",
    "        try:\n",
    "            units = fact_data['facts']['us-gaap'][concept]['units']\n",
    "            unit_key = list(units.keys())[0]\n",
    "            latest = units[unit_key][-1]\n",
    "            return {\"val\": latest['val'], \"end\": latest['end'], \"unit\": unit_key}\n",
    "        except: return {\"val\": \"N/A\", \"end\": \"N/A\"}\n",
    "\n",
    "    financials = {\n",
    "        \"Revenue\": get_latest_fact(\"RevenueFromContractWithCustomerExcludingAssessedTax\"),\n",
    "        \"NetIncome\": get_latest_fact(\"NetIncomeLoss\"),\n",
    "        \"GrossProfit\": get_latest_fact(\"GrossProfit\"),\n",
    "        \"EPS\": get_latest_fact(\"EarningsPerShareBasic\")\n",
    "    }\n",
    "    \n",
    "    return latest_info, financials\n",
    "\n",
    "# --- 2. ä¸‹è¼‰ PDF ä¸¦ç²¾æº–æå–å…ƒç´  ---\n",
    "\n",
    "def download_and_extract_elements(info):\n",
    "    save_dir = \"./reports\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, info['filename'])\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"âœ… æ‰¾åˆ°æœ¬åœ° PDF å¿«å–: {info['filename']}ï¼Œè·³éä¸‹è¼‰èˆ‡è§£æã€‚\")\n",
    "        return None \n",
    "    \n",
    "    print(f\"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ PDF: {info['url']}\")\n",
    "    res = requests.get(info['url'], headers=HEADERS)\n",
    "    if res.status_code != 200:\n",
    "        fallback_url = info['url'].replace(\"-gen.pdf\", \".pdf\")\n",
    "        res = requests.get(fallback_url, headers=HEADERS)\n",
    "        if res.status_code != 200:\n",
    "            raise Exception(\"ç„¡æ³•ä¸‹è¼‰ PDFã€‚\")\n",
    "    with open(save_path, 'wb') as f: f.write(res.content)\n",
    "    \n",
    "    print(f\"ğŸ“„ æ­£åœ¨é‡æ–°è§£æ PDF ä¸¦è™•ç†é ç¢¼å…ƒæ•¸æ“š: {info['filename']}\")\n",
    "    loader = UnstructuredPDFLoader(save_path, strategy=\"fast\", mode=\"elements\")\n",
    "    elements = loader.load()\n",
    "    \n",
    "    clean_elements = filter_complex_metadata(elements)\n",
    "    \n",
    "    docs_with_page = []\n",
    "    for el in clean_elements:\n",
    "        text = el.page_content.strip()\n",
    "        if len(text) > 50:\n",
    "            docs_with_page.append(el)\n",
    "            \n",
    "    return docs_with_page\n",
    "\n",
    "# --- 3. å»ºç«‹æˆ–è®€å–å‘é‡åº« ---\n",
    "\n",
    "def get_vector_db(docs, info):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=apiKey)\n",
    "    persist_dir = f\"./chroma_db/{info['ticker']}\"\n",
    "    \n",
    "    if os.path.exists(persist_dir) and docs is None:\n",
    "        print(f\"ğŸ“š ç›´æ¥åŠ è¼‰ç¾æœ‰å‘é‡åº«: {persist_dir}\")\n",
    "        return Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "    \n",
    "    print(f\"ğŸ†• å»ºç«‹æ–°çš„å‘é‡åº«: {persist_dir}\")\n",
    "    if os.path.exists(persist_dir):\n",
    "        try:\n",
    "            shutil.rmtree(persist_dir)\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            persist_dir = f\"{persist_dir}_{int(time.time())}\"\n",
    "            \n",
    "    db = Chroma.from_documents(\n",
    "        documents=docs, \n",
    "        embedding=embeddings, \n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    return db\n",
    "\n",
    "# --- 4. æª¢ç´¢é™¤éŒ¯å‡½æ•¸ ---\n",
    "\n",
    "def search_with_debug(db, query, k=5):\n",
    "    \"\"\"\n",
    "    åŸ·è¡Œç›¸ä¼¼åº¦æœå°‹ä¸¦æ‰“å°æ¯å€‹ç‰‡æ®µçš„è©³ç´°å…§å®¹èˆ‡ PDF é ç¢¼ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” æœå°‹å•é¡Œ: {query}\")\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    print(f\"ğŸ± æ‰¾åˆ° {len(docs)} å€‹ç›¸é—œç‰‡æ®µï¼š\")\n",
    "    \n",
    "    for i, doc in enumerate(docs):\n",
    "        page = doc.metadata.get(\"page_number\", \"N/A\")\n",
    "        content = doc.page_content.replace('\\n', ' ')[:200]\n",
    "        \n",
    "        print(f\"--- è­‰æ“š {i+1} (ä¾†æº: {TICKER} è²¡å ±, é ç¢¼: {page}) ---\")\n",
    "        print(f\"{content}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "\n",
    "# --- 6. ç”Ÿæˆå ±å‘Š ---\n",
    "\n",
    "def analyze_and_report(db, financials, info):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=apiKey, temperature=0.3)\n",
    "    \n",
    "    search_query = \"Detailed analysis of Tesla's operational performance, revenue growth factors, and risk outlook.\"\n",
    "    context_docs = db.similarity_search(search_query, k=8)\n",
    "    \n",
    "    context_segments = []\n",
    "    for d in context_docs:\n",
    "        page = d.metadata.get(\"page_number\", \"N/A\")\n",
    "        context_segments.append(f\"[ä¾†æº PDF é ç¢¼: {page}]\\n{d.page_content}\")\n",
    "    \n",
    "    context_text = \"\\n\\n\".join(context_segments)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç¾è‚¡ç ”ç©¶å“¡ã€‚è«‹çµåˆä¸‹æ–¹çš„ã€ŒSEC å®˜æ–¹è²¡å‹™æŒ‡æ¨™ã€èˆ‡ã€Œè²¡å ± PDF å…§å®¹ã€ï¼Œç‚º Tesla (TSLA) æ’°å¯«ä¸­æ–‡åˆ†æã€‚\n",
    "\n",
    "    ### 1. SEC æœ€æ–°è²¡å‹™æ•¸æ“š:\n",
    "    - å ±å‘Šé¡å‹: {form}, æ—¥æœŸ: {date}\n",
    "    - ç¸½ç‡Ÿæ”¶: {rev}, æ·¨åˆ©: {ni}, EPS: {eps}\n",
    "\n",
    "    ### 2. è²¡å ± PDF æª¢ç´¢å…§å®¹:\n",
    "    {context}\n",
    "\n",
    "    ### è¦æ±‚:\n",
    "    - **ç‡Ÿé‹äº®é»**: ç¸½çµæœ¬å­£è¡¨ç¾ã€‚\n",
    "    - **æ·±åº¦è§£æ**: ä½¿ç”¨æ•¸æ“šé…åˆæ–‡æœ¬ï¼Œä¸¦ç²¾ç¢ºæ¨™è¨» [PDF ç¬¬ X é ]ã€‚\n",
    "    - **é¢¨éšªå±•æœ›**: æ ¹æ“š PDF åˆ†ææœªä¾†é¢¨éšªï¼Œä¸¦æ¨™è¨» [PDF ç¬¬ X é ]ã€‚\n",
    "    \"\"\")\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    report = chain.invoke({\n",
    "        \"form\": info['form'], \"date\": info['date'],\n",
    "        \"rev\": financials['Revenue']['val'], \"rev_date\": financials['Revenue']['end'],\n",
    "        \"ni\": financials['NetIncome']['val'], \"ni_date\": financials['NetIncome']['end'],\n",
    "        \"eps\": financials['EPS']['val'],\n",
    "        \"context\": context_text\n",
    "    })\n",
    "    \n",
    "    # print(\"\\nğŸ“Š å°ˆæ¥­åˆ†æå ±å‘Šå·²ç”Ÿæˆã€‚\")\n",
    "    print(\"\\n\" + \"â˜…\"*40)\n",
    "    print(f\"ğŸ“Š {TICKER} {info['form']} å°ˆæ¥­åˆ†æå ±å‘Š (é ç¢¼ç²¾ç¢ºç‰ˆ)\")\n",
    "    print(\"â˜…\"*40)\n",
    "    print(report.content)\n",
    "    return report.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98206bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰¾åˆ°æœ¬åœ° PDF å¿«å–: TSLA_20251231_10-K.pdfï¼Œè·³éä¸‹è¼‰èˆ‡è§£æã€‚\n",
      "ğŸ“š ç›´æ¥åŠ è¼‰ç¾æœ‰å‘é‡åº«: ./chroma_db/TSLA\n",
      "\n",
      "â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
      "ğŸ“Š TSLA 10-K å°ˆæ¥­åˆ†æå ±å‘Š (é ç¢¼ç²¾ç¢ºç‰ˆ)\n",
      "â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
      "### ç‡Ÿé‹äº®é»\n",
      "\n",
      "åœ¨2025è²¡å¹´ï¼ŒTesla (TSLA) çš„ç¸½ç‡Ÿæ”¶é”åˆ°948.27å„„ç¾å…ƒï¼Œæ·¨åˆ©æ½¤ç‚º37.94å„„ç¾å…ƒï¼Œæ¯è‚¡ç›ˆé¤˜ï¼ˆEPSï¼‰ç‚º1.18ç¾å…ƒã€‚é€™äº›æ•¸æ“šé¡¯ç¤ºå‡ºTeslaåœ¨é›»å‹•è»Šå¸‚å ´çš„å¼·å‹å¢é•·èƒ½åŠ›ï¼Œå„˜ç®¡é¢è‡¨è‘—æ¿€çƒˆçš„å¸‚å ´ç«¶çˆ­å’Œä¸ç¢ºå®šçš„ç¶“æ¿Ÿç’°å¢ƒï¼Œä»ç„¶èƒ½å¤ ä¿æŒç©©å®šçš„ç›ˆåˆ©èƒ½åŠ›ã€‚\n",
      "\n",
      "### æ·±åº¦è§£æ\n",
      "\n",
      "Teslaåœ¨2025å¹´çš„è²¡å‹™è¡¨ç¾é¡¯ç¤ºå‡ºå…¶åœ¨å¸‚å ´ä¸­çš„ç«¶çˆ­å„ªå‹¢ã€‚ç¸½ç‡Ÿæ”¶çš„å¢é•·é¡¯ç¤ºå‡ºå…¶ç”¢å“å’Œæœå‹™çš„å¸‚å ´éœ€æ±‚æŒçºŒä¸Šå‡ã€‚æ·¨åˆ©æ½¤çš„å¢é•·å‰‡åæ˜ äº†å…¬å¸åœ¨æˆæœ¬æ§åˆ¶å’Œé‹ç‡Ÿæ•ˆç‡æ–¹é¢çš„æ”¹å–„ã€‚æ ¹æ“šè²¡å ±å…§å®¹ï¼ŒTeslaçš„ç”¢å“ã€æ¥­å‹™å’Œç¶“ç‡Ÿæˆæœå—åˆ°å¤šæ–¹è©•è«–ï¼Œé€™äº›è©•è«–å¯èƒ½åŒ…æ‹¬æ‰¹è©•ï¼Œä¸¦å¯èƒ½å°å“ç‰Œå’Œæ¥­å‹™é€ æˆè² é¢å½±éŸ¿ [PDF ç¬¬20é ]ã€‚æ­¤å¤–ï¼ŒTeslaçš„æˆåŠŸåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾è³´æ–¼Elon Muskçš„é ˜å°ï¼Œä¸¦ä¸”å…¬å¸éœ€è¦å¸å¼•å’Œç•™ä½å¤§é‡çš„å·¥ç¨‹ã€è£½é€ ã€ç‡ŸéŠ·å’ŒéŠ·å”®äººæ‰ï¼Œä»¥æ”¯æŒå…¶é«˜ç”¢é‡ç”¢å“çš„éŠ·å”®å’Œå¸‚å ´æ“´å¼µ [PDF ç¬¬21é ]ã€‚\n",
      "\n",
      "### é¢¨éšªå±•æœ›\n",
      "\n",
      "æœªä¾†ï¼ŒTeslaé¢è‡¨å¤šé‡é¢¨éšªã€‚é¦–å…ˆï¼Œå…¬å¸çš„é•·æœŸè²¡å‹™ç©©å®šæ€§å’Œæ¥­å‹™å‰æ™¯å—åˆ°å¤šæ–¹é—œæ³¨ï¼Œç¶­æŒå¸‚å ´ä¿¡å¿ƒå¯èƒ½å…·æœ‰æŒ‘æˆ°æ€§ [PDF ç¬¬20é ]ã€‚å…¶æ¬¡ï¼ŒTeslaçš„æœªä¾†æˆåŠŸä¾è³´æ–¼å¸å¼•å’Œç•™ä½é—œéµäººæ‰çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨è¨ˆåŠƒä¸­çš„é«˜ç”¢é‡ç”¢å“éŠ·å”®å’Œå¸‚å ´æ“´å¼µä¸­ [PDF ç¬¬21é ]ã€‚æ­¤å¤–ï¼Œé”æˆé‹ç‡Ÿé‡Œç¨‹ç¢‘çš„å¯èƒ½æ€§åŸºæ–¼å°ç”¢å“è·¯ç·šåœ–ã€ç›£ç®¡ç’°å¢ƒã€è¡Œæ¥­è¶¨å‹¢å’Œç«¶çˆ­ç’°å¢ƒçš„ä¸»è§€è©•ä¼°ï¼Œé€™äº›å› ç´ å¯èƒ½æœƒå½±éŸ¿å…¬å¸çš„è²¡å‹™é æ¸¬ [PDF ç¬¬86é ]ã€‚å› æ­¤ï¼ŒTeslaéœ€è¦åœ¨é€™äº›æ–¹é¢æ¡å–ç©æ¥µæªæ–½ï¼Œä»¥æ¸›å°‘å°å…¶æ¥­å‹™å’Œè²¡å‹™ç‹€æ³çš„æ½›åœ¨å½±éŸ¿ã€‚\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # æµç¨‹åˆå§‹åŒ–\n",
    "         # 1. æª¢æŸ¥ SEC æœ€æ–°ç‹€æ…‹\n",
    "        info, facts = get_latest_sec_data()\n",
    "        \n",
    "        # 2. æª¢æŸ¥ PDFï¼ˆè‹¥å·²æœ‰å¿«å–å‰‡å‚³å› Noneï¼‰\n",
    "        docs = download_and_extract_elements(info)\n",
    "        \n",
    "        # 3. å»ºç«‹æˆ–è®€å–å‘é‡åº«ï¼ˆè‹¥ docs ç‚º None å‰‡ç›´æ¥åŠ è¼‰ï¼‰\n",
    "        db = get_vector_db(docs, info)\n",
    "        \n",
    "        # 4. ç”Ÿæˆå ±å‘Š\n",
    "        analyze_and_report(db, facts, info)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840b0ac",
   "metadata": {},
   "source": [
    "# RAGASè©•ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3165243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval_ragas(db, questions, ground_truths):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ RAGAS è¡¡é‡æª¢ç´¢çµæœã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ§ª é–‹å§‹é€²è¡Œ RAGAS æ·±åº¦è©•ä¼°...\")\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=apiKey)\n",
    "    \n",
    "    data_samples = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "        \"ground_truth\": []\n",
    "    }\n",
    "    \n",
    "    for q, gt in zip(questions, ground_truths):\n",
    "        # æª¢ç´¢å‰ 3 å€‹ç‰‡æ®µé€²è¡Œè©•ä¼°\n",
    "        retrieved_docs = db.similarity_search(q, k=3)\n",
    "        contexts = [d.page_content for d in retrieved_docs]\n",
    "        \n",
    "        # ç²å– LLM ç­”æ¡ˆä»¥ä¾¿è¨ˆç®—ç›¸é—œæ€§\n",
    "        prompt = f\"è«‹æ ¹æ“šä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”å•é¡Œ: {q}\\n\\nä¸Šä¸‹æ–‡: {' '.join(contexts)}\"\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        data_samples[\"question\"].append(q)\n",
    "        data_samples[\"answer\"].append(response.content)\n",
    "        data_samples[\"contexts\"].append(contexts)\n",
    "        data_samples[\"ground_truth\"].append(gt)\n",
    "        \n",
    "    dataset = Dataset.from_dict(data_samples)\n",
    "    \n",
    "    try:\n",
    "        # åŸ·è¡Œè©•ä¼°\n",
    "        score = evaluate(\n",
    "            dataset,\n",
    "            metrics=[\n",
    "                faithfulness, \n",
    "                answer_relevancy, \n",
    "                context_precision, \n",
    "                context_recall\n",
    "            ],\n",
    "            llm=llm\n",
    "        )\n",
    "        print(\"\\nâœ… è©•ä¼°å®Œæˆï¼\")\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ RAGAS åŸ·è¡Œå¤±æ•—: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d2c0768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/7clwcy050c7gyjz5lqt8kk_00000gn/T/ipykernel_3193/2080436868.py:2: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import (\n",
      "/var/folders/rs/7clwcy050c7gyjz5lqt8kk_00000gn/T/ipykernel_3193/2080436868.py:2: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import (\n",
      "/var/folders/rs/7clwcy050c7gyjz5lqt8kk_00000gn/T/ipykernel_3193/2080436868.py:2: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import (\n",
      "/var/folders/rs/7clwcy050c7gyjz5lqt8kk_00000gn/T/ipykernel_3193/2080436868.py:2: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª é–‹å§‹é€²è¡Œ RAGAS æ·±åº¦è©•ä¼°...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a1dd90089439990b8e4ad4896af5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… è©•ä¼°å®Œæˆï¼\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š RAGAS æ·±åº¦è©•ä¼°çµæœå ±è¡¨\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.944241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_precision  context_recall  faithfulness  answer_relevancy\n",
       "0                0.0             0.0      0.583333          0.944241\n",
       "1                0.0             0.0      1.000000          0.994168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ ç¶œåˆç¶­åº¦å¹³å‡åˆ†ï¼š\n",
      "------------------------------\n",
      "context_precision : 0.0000  âŒ éœ€å¤§å¹…èª¿æ•´\n",
      "context_recall    : 0.0000  âŒ éœ€å¤§å¹…èª¿æ•´\n",
      "faithfulness      : 0.7917  âš ï¸ å¾…å„ªåŒ–\n",
      "answer_relevancy  : 0.9692  âœ… å„ªç§€\n",
      "\n",
      "ğŸ’¡ è§£è®€å°æ’‡æ­¥ï¼š\n",
      "- å¦‚æœ Context Recall ä½ï¼šä»£è¡¨æª¢ç´¢å™¨æ²’æŠ“åˆ° PDF è£¡çš„æ­£ç¢ºé é¢ï¼Œè€ƒæ…®å¢åŠ  k å€¼ã€‚\n",
      "- å¦‚æœ Faithfulness ä½ï¼šä»£è¡¨ AI åœ¨èƒ¡èªªå…«é“ï¼ˆå¹»è¦ºï¼‰ï¼Œéœ€æª¢æŸ¥ Prompt æˆ– Context æ˜¯å¦å¤ªäº‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. ç¢ºä¿æœ€æ–°æŒ‡æ¨™å·²æ­£ç¢ºå°å…¥ (åœ¨ Cell é ‚éƒ¨å†æ¬¡æª¢æŸ¥)\n",
    "from ragas.metrics import (\n",
    "    faithfulness, \n",
    "    answer_relevancy, \n",
    "    context_precision, \n",
    "    context_recall\n",
    ")\n",
    "\n",
    "# 2. å®šç¾©æ¸¬è©¦è³‡æ–™\n",
    "test_questions = [\n",
    "    \"What are Tesla's primary revenue sources?\",\n",
    "    \"What were the key risks mentioned in the latest report?\"\n",
    "]\n",
    "test_truths = [\n",
    "    \"Tesla generates revenue from automotive sales, energy storage, and services.\",\n",
    "    \"Key risks include supply chain disruptions, competition in EV market, and regulatory changes.\"\n",
    "]\n",
    "\n",
    "# 3. åŸ·è¡Œè©•ä¼°\n",
    "# ç¢ºä¿ evaluate_retrieval_ragas å…§éƒ¨ä½¿ç”¨çš„æ˜¯ä¸Šé¢å°å…¥çš„å°è±¡\n",
    "result = evaluate_retrieval_ragas(db, test_questions, test_truths)\n",
    "\n",
    "if result:\n",
    "    # å°‡çµæœè½‰ç‚º DataFrame\n",
    "    df = result.to_pandas()\n",
    "    \n",
    "    # å®šç¾©æˆ‘å€‘æƒ³è¦è§€å¯Ÿçš„æ¬„ä½åç¨±\n",
    "    # æ³¨æ„ï¼šRAGAS åœ¨ DataFrame ä¸­çš„æ¬„ä½åé€šå¸¸èˆ‡æŒ‡æ¨™å°è±¡åç¨±ä¸€è‡´\n",
    "    target_cols = [\n",
    "        \"question\", \n",
    "        \"context_precision\", \n",
    "        \"context_recall\", \n",
    "        \"faithfulness\", \n",
    "        \"answer_relevancy\"\n",
    "    ]\n",
    "    \n",
    "    # è‡ªå‹•éæ¿¾æ‰ä¸å­˜åœ¨çš„æ¬„ä½ (é¿å… KeyError)\n",
    "    existing_cols = [c for c in target_cols if c in df.columns]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š RAGAS æ·±åº¦è©•ä¼°çµæœå ±è¡¨\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # é¡¯ç¤ºè¡¨æ ¼ (Jupyter ç‰¹æœ‰å‡½æ•¸)\n",
    "    display(df[existing_cols])\n",
    "    \n",
    "    # 4. æ‰“å°å¹³å‡åˆ†æ•¸èˆ‡è§£è®€å»ºè­°\n",
    "    print(\"\\nğŸ“ˆ ç¶œåˆç¶­åº¦å¹³å‡åˆ†ï¼š\")\n",
    "    print(\"-\" * 30)\n",
    "    for col in existing_cols:\n",
    "        if col != \"question\":\n",
    "            avg_score = df[col].mean()\n",
    "            # ç°¡å–®çš„è§£è®€é‚è¼¯\n",
    "            status = \"âœ… å„ªç§€\" if avg_score >= 0.8 else \"âš ï¸ å¾…å„ªåŒ–\" if avg_score >= 0.5 else \"âŒ éœ€å¤§å¹…èª¿æ•´\"\n",
    "            print(f\"{col:18}: {avg_score:.4f}  {status}\")\n",
    "            \n",
    "    print(\"\\nğŸ’¡ è§£è®€å°æ’‡æ­¥ï¼š\")\n",
    "    print(\"- å¦‚æœ Context Recall ä½ï¼šä»£è¡¨æª¢ç´¢å™¨æ²’æŠ“åˆ° PDF è£¡çš„æ­£ç¢ºé é¢ï¼Œè€ƒæ…®å¢åŠ  k å€¼ã€‚\")\n",
    "    print(\"- å¦‚æœ Faithfulness ä½ï¼šä»£è¡¨ AI åœ¨èƒ¡èªªå…«é“ï¼ˆå¹»è¦ºï¼‰ï¼Œéœ€æª¢æŸ¥ Prompt æˆ– Context æ˜¯å¦å¤ªäº‚ã€‚\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ç„¡æ³•å–å¾—è©•ä¼°çµæœã€‚è«‹æª¢æŸ¥ï¼š\")\n",
    "    print(\"1. OpenAI API Key æ˜¯å¦æ­£ç¢ºã€‚\")\n",
    "    print(\"2. ç¶²è·¯æ˜¯å¦èƒ½é€£é€šè‡³ HuggingFace/OpenAIã€‚\")\n",
    "    print(\"3. æ˜¯å¦å·²å®‰è£æœ€æ–°ç‰ˆ ragas (pip install ragas -U)ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
